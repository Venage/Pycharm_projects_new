{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium_pages import UseSelenium\n",
    "from selenium_product import UseSelenium as UseSelenium_2\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from lib.csv_handler import CsvHandler\n",
    "import requests\n",
    "import openpyxl.drawing.image\n",
    "from PIL import Image as pilIm\n",
    "from openpyxl import load_workbook\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from openpyxl.styles import (\n",
    "                        PatternFill, Border, Side,\n",
    "                        Alignment, Font, GradientFill\n",
    "                        )\n",
    "\n",
    "\n",
    "global num_tovarov,class_pars,filename_final,image_path\n",
    "start_time = time.time()\n",
    "\n",
    "url = 'https://www.ozon.ru/category/zerkala-15051/'\n",
    "class_in_page = 'widget-search-result-container ku5'\n",
    "filename_final = r'C:\\PyProjects\\poject_1\\tural\\ozon\\ozon_дом_зеркала.xlsx'\n",
    "image_path = r'C:\\PyProjects\\poject_1\\tural\\ozon\\images_2\\phone'\n",
    "class_pars = ['k5u','k8t']\n",
    "num_tovarov = 10\n",
    "\n",
    "def download_category_html(url):\n",
    "\n",
    "    # Ограничим парсинг первыми 10 страницами\n",
    "    MAX_PAGE = 1\n",
    "    i = 1\n",
    "    while i <= MAX_PAGE:\n",
    "        filename = f'page_' + str(i) + '.html'\n",
    "        if i == 1:\n",
    "            UseSelenium(url, filename).save_page()\n",
    "        else:\n",
    "            url_param = url + '?page=' + str(i)\n",
    "            UseSelenium(url_param, filename).save_page()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "def get_pages() -> list:\n",
    "    return glob.glob('C:/PyProjects/poject_1/tural/ozon/pages/*.html')\n",
    "\n",
    "\n",
    "def get_html(page: str):\n",
    "    with open(page, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def parse_data(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        links = []\n",
    "        products = soup.find('div', attrs={'class', 'k5u'}).find_all('a')  # k7r\n",
    "        for product in products:\n",
    "            links.append(product.get('href').split('?')[0])\n",
    "    except:\n",
    "        print('НЕ t6k')\n",
    "        links = []\n",
    "        products = soup.find('div', attrs={'class', 'k8t'}).find_all('a')  # k7r\n",
    "        for product in products:\n",
    "            links.append(product.get('href').split('?')[0])\n",
    "\n",
    "        # print('НЕ t6k, k8t')\n",
    "\n",
    "    #return set(links)\n",
    "    final_links = []\n",
    "    min_len = len(links[0])/2\n",
    "    for link in links:\n",
    "        if (link not in final_links) and (len(link) > min_len):\n",
    "            final_links.append(link)\n",
    "\n",
    "    return final_links[:10]\n",
    "\n",
    "\n",
    "def get_product_links() -> list:\n",
    "    with open(r'C:\\PyProjects\\poject_1\\tural\\ozon\\product_links.txt', 'r', encoding='utf-8') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def data_parsing(product: str, i: int, filename: str) -> None:\n",
    "    url = 'https://www.ozon.ru/api/composer-api.bx/page/json/v2' \\\n",
    "          f'?url={product}'\n",
    "\n",
    "    filename = filename + str(i) + '.html'\n",
    "    UseSelenium_2(url, filename).save_page()\n",
    "\n",
    "def save_lincs_to_txt(all_links):\n",
    "    with open(os.getcwd()+'\\product_links.txt', 'w', encoding='utf-8') as f:\n",
    "        for link in all_links:\n",
    "            f.write(link + '\\n')\n",
    "\n",
    "\n",
    "def get_products() -> list:\n",
    "    return glob.glob('products/*.html')\n",
    "\n",
    "def get_json(filename_final: str) -> dict:\n",
    "    with open(filename_final, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        return json.loads(data)\n",
    "\n",
    "def parse_data_product(data: dict) -> dict:\n",
    "    widgets = data.get('widgetStates')\n",
    "    for key, value in widgets.items():\n",
    "        if 'webProductHeading' in key:\n",
    "            title = json.loads(value).get('title')\n",
    "        if 'webSale' in key:\n",
    "            prices = json.loads(value).get('offers')[0]\n",
    "            if prices.get('price'):\n",
    "                price = re.search(r'[0-9]+', prices.get('price').replace(u'\\u2009', ''))[0]\n",
    "            else:\n",
    "                price = 0\n",
    "            if prices.get('originalPrice'):\n",
    "                discount_price = re.search(r'[0-9]+', prices.get('originalPrice').replace(u'\\u2009', ''))[0]\n",
    "            else:\n",
    "                discount_price = 0\n",
    "        if 'webGallery' in key:\n",
    "            url_pic = json.loads(value).get('coverImage')\n",
    "\n",
    "    layout = json.loads(data.get('layoutTrackingInfo'))\n",
    "    brand = layout.get('brandName')\n",
    "    category = layout.get('categoryName')\n",
    "    sku = layout.get('sku')\n",
    "    url = layout.get('currentPageUrl')\n",
    "\n",
    "\n",
    "    product = {\n",
    "        'img': '',\n",
    "        'title': title,\n",
    "        'price': price,\n",
    "        'discount_price': discount_price,\n",
    "        'brand': brand,\n",
    "        'category': category,\n",
    "        'sku': sku,\n",
    "        'url': url[:-1],\n",
    "        'url_pic': url_pic\n",
    "    }\n",
    "    return product\n",
    "\n",
    "\n",
    "def download_img():\n",
    "    df_img = pd.read_excel(filename_final)\n",
    "    img_list = df_img['url_pic'].to_list()\n",
    "    j = 0\n",
    "    for i in img_list:\n",
    "        j += 1\n",
    "        img_data = requests.get(i).content\n",
    "        with open(image_path+'\\image_name_'+str(j)+'.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "\n",
    "\n",
    "def change_size(img, shirina):\n",
    "    k = img.width/shirina\n",
    "    img.width = shirina\n",
    "    img.height = img.height/k\n",
    "    return img\n",
    "\n",
    "def img_to_excel():\n",
    "    path = os.getcwd()\n",
    "    shirina = 150\n",
    "    kachestvo = 45\n",
    "\n",
    "    os.mkdir(\"bad_images\")\n",
    "    spis = os.listdir(path+'\\\\'+'images_2')\n",
    "\n",
    "    for papka in spis:\n",
    "        os.mkdir('bad_images\\\\'+papka)\n",
    "        files = os.listdir(path+'\\\\'+'images_2\\\\'+papka)\n",
    "\n",
    "    for i in files:\n",
    "        try:\n",
    "            image = pilIm.open(path+'\\\\'+'images_2\\\\'+papka+'\\\\'+i)\n",
    "            image.save(path+'\\\\'+'bad_images\\\\'+papka+'\\\\'+i, quality = kachestvo)\n",
    "        except:\n",
    "            print('Ошибка с картинкой')\n",
    "            return 1\n",
    "\n",
    "    spis = os.listdir(path+'\\\\'+'bad_images')\n",
    "    for papka in spis:\n",
    "        files = os.listdir('bad_images\\\\'+papka)\n",
    "\n",
    "        #сортировка названий изображений\n",
    "        def numerical_sort(value: str) -> list:\n",
    "            parts = re.compile(r'(\\d+)').split(value)\n",
    "            parts[1::2] = map(int, parts[1::2])\n",
    "            return parts\n",
    "\n",
    "        files = sorted(files, key=numerical_sort)\n",
    "\n",
    "        wb = load_workbook(filename_final)\n",
    "        sheet = wb.active\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            img = openpyxl.drawing.image.Image('bad_images\\\\'+papka+'\\\\'+files[i])\n",
    "            img = change_size(img, shirina)\n",
    "            sheet.add_image(img, 'A%d'%(i+2))\n",
    "\n",
    "            sheet.row_dimensions[i+2].height = img.height*0.75\n",
    "        sheet.column_dimensions['A'].width = img.width*0.143\n",
    "        print(files)\n",
    "        wb.save(filename_final)\n",
    "\n",
    "    # for papka in spis:\n",
    "    #     files = os.listdir('bad_images\\\\' + papka)\n",
    "    #     for i in range(len(files)):\n",
    "    #         os.remove('bad_images\\\\'+papka+'\\\\'+files[i])\n",
    "    #     os.rmdir('bad_images\\\\'+papka)\n",
    "    # os.rmdir(\"bad_images\")\n",
    "    return 0\n",
    "\n",
    "def delete_pictures():\n",
    "    files = glob.glob(image_path+'/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "def format_excel():\n",
    "    wb = load_workbook(filename_final)\n",
    "    sheet = wb.active\n",
    "    sheet.row_dimensions[1].height = 20\n",
    "    # ffcc00 - оранжевый\n",
    "    sheet['A1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['B1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['C1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['D1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['E1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['F1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['G1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['H1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    sheet['I1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    #sheet['J1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "    #sheet['K1'].fill = PatternFill('solid', fgColor='ffcc00')\n",
    "\n",
    "    for row in sheet[2:sheet.max_row]:  # skip the header\n",
    "\n",
    "        row[1].alignment = Alignment(horizontal=\"left\", vertical=\"center\")\n",
    "        row[2].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        row[3].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        row[4].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        row[5].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        row[6].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        row[7].alignment = Alignment(horizontal=\"left\", vertical=\"center\")\n",
    "        row[8].alignment = Alignment(horizontal=\"left\", vertical=\"center\")\n",
    "        #row[9].alignment = Alignment(horizontal=\"left\", vertical=\"center\")\n",
    "        #row[10].alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    for i in range(sheet.max_row):\n",
    "        sheet.cell(row = i+1, column=10).value = ' '\n",
    "\n",
    "    a = 20\n",
    "    sheet.column_dimensions['B'].width = 50\n",
    "    sheet.column_dimensions['C'].width = a\n",
    "    sheet.column_dimensions['D'].width = a\n",
    "    sheet.column_dimensions['E'].width = a\n",
    "    sheet.column_dimensions['F'].width = a\n",
    "    sheet.column_dimensions['G'].width = a\n",
    "    sheet.column_dimensions['H'].width = 10\n",
    "    sheet.column_dimensions['I'].width = 10\n",
    "\n",
    "    wb.save(filename_final)\n",
    "\n",
    "def del_file_if_exsict():\n",
    "    if os.path.isfile(filename_final):\n",
    "        os.remove(filename_final)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def del_bad_images():\n",
    "    try:\n",
    "        shutil.rmtree(os.getcwd()+'/bad_images')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    download_category_html(url)\n",
    "    pages = get_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['C:/PyProjects/poject_1/tural/ozon/pages\\\\page_1.html']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "all_links = []\n",
    "for page in pages:\n",
    "    html = get_html(page)\n",
    "    links = parse_data(html)\n",
    "    links = links[:num_tovarov]\n",
    "    all_links = all_links + list(links)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "save_lincs_to_txt(all_links)\n",
    "products = get_product_links()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 1\n",
    "for product in products:\n",
    "    data_parsing(product, i, filename='product_')\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "i = 1\n",
    "for product in products:\n",
    "    data_parsing(product, i, filename='product_')\n",
    "    i += 1\n",
    "\n",
    "products = get_products()\n",
    "\n",
    "df_all = pd.DataFrame(columns=['img','title', 'price', 'discount_price', 'brand', 'category', 'sku', 'url', 'url_pic'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "for product in products:\n",
    "    try:\n",
    "        product_json = get_json(product)\n",
    "        result = parse_data_product(product_json)\n",
    "        df_all.loc[i] = list(result.values())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(df_all)\n",
    "del_file_if_exsict()\n",
    "df_all.to_excel(filename_final, index=False)\n",
    "\n",
    "del_bad_images()\n",
    "download_img()\n",
    "img_to_excel()\n",
    "delete_pictures()\n",
    "del_bad_images()\n",
    "#delete_pictures()\n",
    "\n",
    "\n",
    "format_excel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
