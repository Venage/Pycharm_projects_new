{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as progress\n",
    "from sklearn.decomposition.pca import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 288 ms, total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dir = '../Netology/Data/Whale/train'\n",
    "test_dir = '../Netology/Data/Whale/test'\n",
    "\n",
    "imgs_train = [cv2.imread(train_dir + '/' + file, cv2.IMREAD_GRAYSCALE) for file in os.listdir(train_dir)]\n",
    "\n",
    "min_cols = 138\n",
    "min_rows = 54\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compressed_train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ef3b88aa4e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_train_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compressed_train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(compressed_train_imgs[8000], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.resize(imgs_train[99],(130,75)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_pics = [i for i in range(len(imgs_train)) if (imgs_train[i].shape[0]>=min_rows)and(imgs_train[i].shape[1]>=min_cols)]\n",
    "imgs_train = [imgs_train[i] for i in good_pics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compressed_train_imgs = [cv2.resize(img, (256, 256)) for img in imgs_train]\n",
    "del imgs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [file for file in os.listdir(train_dir)]\n",
    "filenames = [filenames[i] for i in good_pics]\n",
    "filenames_test = [file for file in os.listdir(test_dir)]\n",
    "X_train = [img.ravel() for img in compressed_train_imgs]\n",
    "df = pd.DataFrame(data = filenames, columns = ['FileName'])\n",
    "data2 = pd.read_csv('../Netology/Data/Whale/train.csv',names = ['FileName','WhaleID'])\n",
    "data = data2.merge(df, on = 'FileName')\n",
    "data = data.drop('FileName',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"#Extract filenames to later associate to whale IDs\n",
    "filenames = [file for file in os.listdir(train_dir)]\n",
    "filenames = [filenames[i] for i in good_pics]\n",
    "filenames_test = [file for file in os.listdir(test_dir)]\n",
    "#Convert images into pandas dataframe format for learning the model\n",
    "df1 = pd.DataFrame(data = [img.ravel() for img in compressed_train_imgs])\n",
    "df2 = pd.DataFrame(data = filenames, columns = ['FileName'])\n",
    "data1 = pd.concat([df2,df1],axis = 1)\n",
    "#Obtain filenames, indexed by whale IDs\n",
    "data2 = pd.read_csv('./train.csv',names = ['FileName','WhaleID'])\n",
    "#Map whale IDs to images via filenames (index of data1 is matched to value of data2)\n",
    "data = data2.merge(data1, on = 'FileName')\n",
    "data = data.drop('FileName',axis = 1)\n",
    "del compressed_train_imgs, df1, df2, data1, data2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del compressed_train_imgs, df, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = data['WhaleID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 100, whiten = True)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('pca',pca),\n",
    "                ('logreg',logreg),\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_test = [cv2.imread(test_dir + '/' + file, cv2.IMREAD_GRAYSCALE) for file in os.listdir(test_dir)]\n",
    "compressed_test_imgs = [cv2.resize(img, (256, 256)) for img in imgs_test]\n",
    "del imgs_test\n",
    "\n",
    "X_test = [img.ravel() for img in compressed_test_imgs]\n",
    "\n",
    "del compressed_test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15610"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame(data = [clf.classes_[np.argsort(y_preds[i,:])[-5:]] for i in range(y_preds.shape[0])],\n",
    "                       index = filenames_test)\n",
    "def list_to_str(L):\n",
    "    string = \"\"\n",
    "    for word in L:\n",
    "        string = string + word + \" \"\n",
    "    return(string)\n",
    "        \n",
    "results2 = pd.DataFrame(data = [list_to_str(results.iloc[i].values) for i in range(results.shape[0])],\n",
    "                        index = filenames_test,columns = ['Id'])\n",
    " \n",
    "results2.to_csv('submission.csv', sep = ',', index_label = 'Image', header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
