{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Синтаксический анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google с помощью искусственного интеллекта испек печенье .\n",
      "\n",
      "Овечкин стал первой звездой дня в НХЛ .\n",
      "\n",
      "На Кубани задержали подозреваемого в двойном убийстве . \n",
      "\n",
      "В Ростове суд вынес приговор банде «амазонок» .\n",
      "\n",
      "Чиновники закрасили мемориал жертвам теракта в питерском метро .\n",
      "\n",
      "Клуб «Наполи» продлил контракт с Гуламом .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/sentences.txt') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызов SyntaxNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка результатов парсинга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249     34 103475]\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20 20] domain_sizes: [    37     66     33 103475]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249    449 103475]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Processed 6 documents\n",
      "INFO:tensorflow:Total processed documents: 6\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 48\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.18, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 6 documents\n",
      "INFO:tensorflow:Total processed documents: 6\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 48\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.87, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 6 documents\n",
      "INFO:tensorflow:Total processed documents: 6\n",
      "INFO:tensorflow:num correct tokens: 6\n",
      "INFO:tensorflow:total tokens: 48\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 1.25, eval metric: 12.50%\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/sentences.txt | docker run --rm -i inemo/syntaxnet_rus > data.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOV-тройки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('испек', 'VERB'), 'dobj', ('Google', 'NOUN'))\n",
      "(('испек', 'VERB'), 'nmod', ('помощью', 'NOUN'))\n",
      "(('помощью', 'NOUN'), 'case', ('с', 'ADP'))\n",
      "(('помощью', 'NOUN'), 'nmod', ('интеллекта', 'NOUN'))\n",
      "(('интеллекта', 'NOUN'), 'amod', ('искусственного', 'ADJ'))\n",
      "(('испек', 'VERB'), 'nsubj', ('печенье', 'NOUN'))\n",
      "(('испек', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "               испек                           \n",
      "   ______________|__________                    \n",
      "  |       |      |       помощью               \n",
      "  |       |      |     _____|__________         \n",
      "  |       |      |    |            интеллекта  \n",
      "  |       |      |    |                |        \n",
      "Google печенье   .    с          искусственного\n",
      "\n",
      "None\n",
      "(('стал', 'VERB'), 'nsubj', ('Овечкин', 'NOUN'))\n",
      "(('стал', 'VERB'), 'nmod', ('звездой', 'NOUN'))\n",
      "(('звездой', 'NOUN'), 'amod', ('первой', 'ADJ'))\n",
      "(('звездой', 'NOUN'), 'nmod', ('дня', 'NOUN'))\n",
      "(('звездой', 'NOUN'), 'nmod', ('НХЛ', 'NOUN'))\n",
      "(('НХЛ', 'NOUN'), 'case', ('в', 'ADP'))\n",
      "(('стал', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "             стал             \n",
      "    __________|_______         \n",
      "   |     |         звездой    \n",
      "   |     |     _______|_____   \n",
      "   |     |    |       |    НХЛ\n",
      "   |     |    |       |     |  \n",
      "Овечкин  .  первой   дня    в \n",
      "\n",
      "None\n",
      "(('задержали', 'VERB'), 'nmod', ('Кубани', 'NOUN'))\n",
      "(('Кубани', 'NOUN'), 'case', ('На', 'ADP'))\n",
      "(('задержали', 'VERB'), 'dobj', ('подозреваемого', 'NOUN'))\n",
      "(('подозреваемого', 'NOUN'), 'nmod', ('убийстве', 'NOUN'))\n",
      "(('убийстве', 'NOUN'), 'case', ('в', 'ADP'))\n",
      "(('убийстве', 'NOUN'), 'amod', ('двойном', 'ADJ'))\n",
      "(('задержали', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "    задержали                           \n",
      "  ______|_______________                 \n",
      " |      |         подозреваемого        \n",
      " |      |               |                \n",
      " |    Кубани         убийстве           \n",
      " |      |       ________|___________     \n",
      " .      На     в                 двойном\n",
      "\n",
      "None\n",
      "(('вынес', 'VERB'), 'nmod', ('Ростове', 'NOUN'))\n",
      "(('Ростове', 'NOUN'), 'case', ('В', 'ADP'))\n",
      "(('вынес', 'VERB'), 'nsubj', ('суд', 'NOUN'))\n",
      "(('вынес', 'VERB'), 'dobj', ('приговор', 'NOUN'))\n",
      "(('приговор', 'NOUN'), 'nmod', ('банде', 'NOUN'))\n",
      "(('банде', 'NOUN'), 'nmod', ('«амазонок»', 'NOUN'))\n",
      "(('вынес', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "    вынес                   \n",
      "  ____|_______________       \n",
      " |    |      |     приговор \n",
      " |    |      |        |      \n",
      " |    |   Ростове   банде   \n",
      " |    |      |        |      \n",
      "суд   .      В    «амазонок»\n",
      "\n",
      "None\n",
      "(('закрасили', 'VERB'), 'nsubj', ('Чиновники', 'NOUN'))\n",
      "(('закрасили', 'VERB'), 'dobj', ('мемориал', 'NOUN'))\n",
      "(('закрасили', 'VERB'), 'nmod', ('жертвам', 'NOUN'))\n",
      "(('жертвам', 'NOUN'), 'nmod', ('теракта', 'NOUN'))\n",
      "(('теракта', 'NOUN'), 'nmod', ('метро', 'NOUN'))\n",
      "(('метро', 'NOUN'), 'case', ('в', 'ADP'))\n",
      "(('метро', 'NOUN'), 'amod', ('питерском', 'ADJ'))\n",
      "(('закрасили', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "                   закрасили                      \n",
      "     __________________|____________               \n",
      "    |        |         |         жертвам          \n",
      "    |        |         |            |              \n",
      "    |        |         |         теракта          \n",
      "    |        |         |            |              \n",
      "    |        |         |          метро           \n",
      "    |        |         |       _____|________      \n",
      "Чиновники мемориал     .      в          питерском\n",
      "\n",
      "None\n",
      "(('продлил', 'VERB'), 'nsubj', ('Клуб', 'NOUN'))\n",
      "(('продлил', 'VERB'), 'advmod', ('«Наполи»', 'ADV'))\n",
      "(('продлил', 'VERB'), 'dobj', ('контракт', 'NOUN'))\n",
      "(('контракт', 'NOUN'), 'nmod', ('Гуламом', 'NOUN'))\n",
      "(('Гуламом', 'NOUN'), 'case', ('с', 'ADP'))\n",
      "(('продлил', 'VERB'), 'punct', ('.', 'PUNCT'))\n",
      "     продлил              \n",
      "  ______|____________      \n",
      " |      |      |  контракт\n",
      " |      |      |     |     \n",
      " |      |      |  Гуламом \n",
      " |      |      |     |     \n",
      "Клуб «Наполи»  .     с    \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk import DependencyGraph\n",
    "import codecs\n",
    "\n",
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in codecs.open('data.conll', 'r', 'utf-8'):\n",
    "    if len(line) == 1:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)\n",
    "\n",
    "deps = []\n",
    "for sentence in processed_sentences:\n",
    "    s = u\"\"\n",
    "    for line in sentence:\n",
    "        s += u\"\\t\".join(line) + u'\\n'\n",
    "    deps.append(s)\n",
    "\n",
    "for sent_dep in deps:\n",
    "    graph = DependencyGraph(tree_str=sent_dep)\n",
    "    for triple in graph.triples():\n",
    "        if triple:\n",
    "            print(triple)\n",
    "    tree = graph.tree()\n",
    "    print(tree.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "испек {'subj': 'печенье', 'obj': 'Google'}\n",
      "стал {'subj': 'Овечкин', 'obj': ''}\n",
      "задержали {'subj': '', 'obj': 'подозреваемого'}\n",
      "вынес {'subj': 'суд', 'obj': 'приговор'}\n",
      "закрасили {'subj': 'Чиновники', 'obj': 'мемориал'}\n",
      "продлил {'subj': 'Клуб', 'obj': 'контракт'}\n"
     ]
    }
   ],
   "source": [
    "for sent_dep in deps:\n",
    "    graph = DependencyGraph(tree_str=sent_dep)\n",
    "    sov = {}\n",
    "    for triple in graph.triples():\n",
    "        if triple:\n",
    "            if triple[0][1] == 'VERB':\n",
    "                sov[triple[0][0]] = {'subj':'','obj':''}\n",
    "    for triple in graph.triples():\n",
    "        if triple:\n",
    "            if triple[1] == 'nsubj':\n",
    "                if triple[0][1] == 'VERB':\n",
    "                    sov[triple[0][0]]['subj']  = triple[2][0]\n",
    "            if triple[1] == 'dobj':\n",
    "                if triple[0][1] == 'VERB':\n",
    "                    sov[triple[0][0]]['obj'] = triple[2][0]\n",
    "\n",
    "    for verb in sov:\n",
    "        print(verb,sov[verb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Измените код выше так, чтобы учитывались:\n",
    "    1. Однородные члены предложения \n",
    "        * (парк, площадка), (Германия, Щвейцария)\n",
    "    2. Сложные сказуемые \n",
    "        * (начнет продавать), (запретил провозить)\n",
    "    3. Непрямые объекты\n",
    "        * (едет, Польшу), (спел, скандале)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
